# 自然语言处理

!> 学习 **NNLM > Word2Vec > Seq2Seq > Seq2Seq with Attention > Transformer > Elmo > GPT > BERT**

## 一、学习资源

* [Introduction to TensorFlow Text](https://tensorflow.google.cn/text/guide/tf_text_intro)
* [TensorFlow text processing tutorials](https://tensorflow.google.cn/text/tutorials)

**论文**

* 🌷CBOW | Skip-gram [Efficient Estimation of Word Representations in Vector Space](papers/arxiv.org.pdf.1301.3781v3.pdf ':ignore')
* 🌷Transformer [Attention Is All You Need](papers/arxiv.org.pdf.1706.03762v7.pdf ':ignore')
* 🌷GPT [Improving Language Understanding by Generative Pre-Training](papers/language_understanding_paper.pdf ':ignore')
* 🌷BERT [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](papers/arxiv.org.pdf.1810.04805v2.pdf ':ignore')

## 二、课前准备

安装环境

```sh

pip install tensorflow  -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install tensorflow_datasets  -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install tensorflow_text  -i https://pypi.tuna.tsinghua.edu.cn/simple

```

## 三、练习

代码在群中下载

* word2vec.ipynb
* word_embeddings.ipynb
* warmstart_embedding_matrix.ipynb
