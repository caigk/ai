# å¤§æ¨¡å‹åº”ç”¨å¼€å‘agent

## ä¸€ã€å­¦ä¹ èµ„æº

* [llama-cpp-agent github](https://github.com/Maximilian-Winter/llama-cpp-agent)
* [OpenAgents github](https://github.com/xlang-ai/OpenAgents) ğŸ“„[paper](spapers\agent\arxiv.org.pdf.2310.10634v1.pdf ':ignore') 
* [camel-ai.org](https://www.camel-ai.org/)
* [camel github](https://github.com/camel-ai/camel)  ğŸ“„[paper](papers\agent\arxiv.org.pdf.2303.17760v2.pdf ':ignore') 
* [AutoGPT github](https://github.com/Significant-Gravitas/AutoGPT)ğŸ’¯
* [babyagi github](https://github.com/yoheinakajima/babyagi)
* [å°é•‡](https://github.com/joonspk-research/generative_agents)
* [agents github](https://github.com/aiwaves-cn/agents) Agents 2.0: Symbolic Learning Enables Self-Evolving Agents
* [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)

**è®ºæ–‡**

* [An LLM Compiler for Parallel Function Calling](papers\agent\arxiv.org.pdf.2312.04511v3.pdf ':ignore')
* [Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents](papers\agent\Describe_Explain_Plan_and_Select_Interactive_Plann.pdf ':ignore')

![ananomy](images/ananomy.png)

## äºŒã€langchainä¸­agentå®ç°

### åŠ¨ä½œä»£ç†äººï¼ˆAction agentsï¼‰

åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸Šï¼Œä½¿ç”¨æ‰€æœ‰å…ˆå‰åŠ¨ä½œçš„è¾“å‡ºå†³å®šä¸‹ä¸€ä¸ªåŠ¨ä½œã€‚

1. æ¥æ”¶ç”¨æˆ·è¾“å…¥
1. å†³å®šæ˜¯å¦ä½¿ç”¨ä»»ä½•å·¥å…·ä»¥åŠå·¥å…·è¾“å…¥
1. è°ƒç”¨å·¥å…·å¹¶è®°å½•è¾“å‡ºï¼ˆä¹Ÿç§°ä¸ºâ€œè§‚å¯Ÿç»“æœâ€ï¼‰
1. ä½¿ç”¨å·¥å…·å†å²è®°å½•ã€å·¥å…·è¾“å…¥å’Œè§‚å¯Ÿç»“æœå†³å®šä¸‹ä¸€æ­¥
1. é‡å¤æ­¥éª¤ 3-4ï¼Œç›´åˆ°ç¡®å®šå¯ä»¥ç›´æ¥å›åº”ç”¨æˆ·

| type | è¯´æ˜ |
| ---- | ------- |
| zero-shot-react-description |	ä»£ç†ä½¿ç”¨ReActæ¡†æ¶ï¼Œä»…åŸºäºå·¥å…·çš„æè¿°æ¥ç¡®å®šè¦ä½¿ç”¨çš„å·¥å…·.æ­¤ä»£ç†ä½¿ç”¨ ReAct æ¡†æ¶ç¡®å®šä½¿ç”¨å“ªä¸ªå·¥å…· ä»…åŸºäºå·¥å…·çš„æè¿°ã€‚ç¼ºä¹ ä¼šè¯å¼è®°å¿†ã€‚ |
| conversational-react-description |		è¿™ä¸ªä»£ç†ç¨‹åºæ—¨åœ¨ç”¨äºå¯¹è¯ç¯å¢ƒä¸­ã€‚æç¤ºè®¾è®¡æ—¨åœ¨ä½¿ä»£ç†ç¨‹åºæœ‰åŠ©äºå¯¹è¯ã€‚ å®ƒä½¿ç”¨ReActæ¡†æ¶æ¥å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶ä½¿ç”¨å†…å­˜æ¥è®°å¿†å…ˆå‰çš„å¯¹è¯äº¤äº’ã€‚ |
| react-docstore |		è¿™ä¸ªä»£ç†ä½¿ç”¨ReActæ¡†æ¶ï¼Œå¿…é¡»æä¾›ä¸¤ä¸ªå·¥å…·ï¼šä¸€ä¸ªSearchå·¥å…·å’Œä¸€ä¸ªLookupå·¥å…·è‡ªé—®è‡ªç­”ï¼Œä¼šä½¿ç”¨Googleæœç´¢å·¥å…·ã€‚ |
| self-askwith-search |		ä»£ç†ä½¿ç”¨ä¸€ä¸ªè¢«å‘½åä¸ºIntermediate Answerçš„å·¥å…·ã€‚æ ¹æ®éœ€è¦æ‰§è¡Œæœç´¢å’Œæé—®æ­¥éª¤ï¼Œä»¥è·å¾—æœ€ç»ˆç­”æ¡ˆã€‚ |
| chat-zero-shot-react-description |		zero-shotæ„å‘³ç€ä»£ç† (Agents) ä»…åœ¨å½“å‰æ“ä½œä¸Šèµ·ä½œç”¨â€”â€”å®ƒæ²¡æœ‰ è®°å¿†ã€‚ |
| chat-conversational-react-description |		è¯¥ä»£ç†è¢«è®¾è®¡ç”¨äºä¼šè¯è®¾ç½®ã€‚æç¤ºçš„ç›®çš„æ˜¯ä½¿ä»£ç†å…·æœ‰å¸®åŠ©å’Œä¼šè¯æ€§ã€‚å®ƒä½¿ç”¨ReActæ¡†æ¶æ¥å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶ä½¿ç”¨å†…å­˜æ¥è®°ä½ä»¥å‰çš„ä¼šè¯äº¤äº’ã€‚ |
| structured-chat-zero-shot-react-description |		èƒ½å¤Ÿä½¿ç”¨å¤šè¾“å…¥å·¥å…·ï¼Œç»“æ„åŒ–çš„å‚æ•°è¾“å…¥ã€‚ |
| openai-functions |		æŸäº›OpenAIæ¨¡å‹ï¼ˆå¦‚gpt-3.5-turbo-0613å’Œgpt-4-0613ï¼‰å·²ç»æ˜ç¡®åœ°è¿›è¡Œäº†å¾®è°ƒï¼Œå¦‚æœä½¿ç”¨è¿™äº›æ¨¡å‹ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨OpenAI Functions çš„AgentTypeã€‚ |
| openai-multi-functions |		æŸäº›OpenAIæ¨¡å‹ï¼ˆå¦‚gpt-3.5-turbo-0613å’Œgpt-4-0613ï¼‰å·²ç»æ˜ç¡®åœ°è¿›è¡Œäº†å¾®è°ƒï¼Œå¦‚æœä½¿ç”¨è¿™äº›æ¨¡å‹ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨OpenAI Functions çš„AgentTypeã€‚ |

### è®¡åˆ’æ‰§è¡Œä»£ç†äººï¼ˆPlan-and-execute agentsï¼‰
é¢„å…ˆå†³å®šæ‰€æœ‰åŠ¨ä½œçš„å®Œæ•´é¡ºåºï¼Œç„¶åæŒ‰ç…§è®¡åˆ’æ‰§è¡Œï¼Œè€Œä¸æ›´æ–°è®¡åˆ’ã€‚

1. æ¥æ”¶ç”¨æˆ·è¾“å…¥
1. è§„åˆ’è¦æ‰§è¡Œçš„å…¨éƒ¨æ­¥éª¤åºåˆ—
1. æŒ‰é¡ºåºæ‰§è¡Œæ­¥éª¤ï¼Œå°†è¿‡å»æ­¥éª¤çš„è¾“å‡ºä½œä¸ºæœªæ¥æ­¥éª¤çš„è¾“å…¥



## ä¸‰ã€ollamaæ¨¡æ‹Ÿopenai

### 1.æ‹‰å–æ¨¡å‹
```bash
ollama pull llama3.1

```

### 2.å»ºç«‹modelfileæ–‡ä»¶


```bash
vi gpt-3.5-turbo-16k.modelfile

#####
FROM llama3.1
# sets the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 0.7
# sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token
PARAMETER num_ctx 4096

# sets a custom system message to specify the behavior of the chat assistant
SYSTEM You are Mario from super mario bros, acting as an assistant.

```

### 3.åˆ›å»ºæ¨¡å‹

```bash
ollama create gpt-3.5-turbo-16k --file gpt-3.5-turbo-16k.modelfile
```

### 4.å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
#bash
OPENAI_API_BASE=http://ai.baitech.com.cn:9901/v1
OPENAI_API_KEY=ollama
```

```bat
REM command
set BASE_URL=http://ai.baitech.com.cn:9901/v1
set OPENAI_API_KEY=ollama
```

```powershell
#powershell
$env:BASE_URL="http://ai.baitech.com.cn:9901/v1"
$env:OPENAI_API_KEY="ollama"
```


## å››ã€camel
```bash
$env:OPENAI_API_BASE_URL="http://ai.baitech.com.cn:9901/v1"
$env:OPENAI_API_KEY="ollama"

# Clone github repo
git clone -b v0.2.0 https://github.com/camel-ai/camel.git

# Change directory into project directory
cd camel

# Create a conda virtual environment
conda create -p .conda  python=3.10

# Activate CAMEL conda environment
conda activate ./.conda

# Install CAMEL from source
pip install -e .

# Or if you want to use all other extra packages
pip install -e .[all] # (Optional)

```

```bash
#é¡¶éƒ¨åŠ å…¥
#ä¿®æ”¹ä¸ºOLLAMA
from camel.models.model_factory import ModelFactory
from camel.types.enums import ModelPlatformType
ollama_model = ModelFactory.create(
    model_platform=ModelPlatformType.OLLAMA,
    model_type="llama3.1",
    url="http://ai.baitech.com.cn:9901/v1",
    model_config_dict={"temperature": 0.4},
)

#å°¾éƒ¨ä¿®æ”¹
main(model=ollama_model)

#è¿è¡Œ
python examples\single_agent.py


python examples\ai_society\role_playing.py

```

## äº”ã€ChatDev

